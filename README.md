# ğŸ‘ï¸ EyeGlass - Assistente Visual HÃ­brido (MVP)


## Tecnologia Assistiva Inteligente com Arquitetura HÃ­brida (Local + Cloud)

O **EyeGlass** Ã© um par de Ã³culos de tecnologia assistiva projetado para oferecer autonomia a pessoas com deficiÃªncia visual. Ele captura o ambiente em tempo real, identifica obstÃ¡culos e fornece feedback sonoro com instruÃ§Ãµes de navegaÃ§Ã£o (ex: _"Mesa a 3 passos, desvie para a direita"_).

Este MVP demonstra uma arquitetura robusta que alterna entre processamento local de alta precisÃ£o e processamento em nuvem para garantir disponibilidade.

---

## ğŸ“˜ SumÃ¡rio

- [Arquitetura do Sistema](#-Arquitetura-do-Sistema)
- [ConfiguraÃ§Ã£o e InstalaÃ§Ã£o](#-ConfiguraÃ§Ã£o-e-InstalaÃ§Ã£o)
- [Como Usar](#-Como-Usar)
- [Escalabildiade e futuro](#-Escalabilidade-e-Futuro)
- [Estrutura do RepositÃ³rio](#-Estrutura-do-RepositÃ³rio)


---
## ğŸš€ Arquitetura do Sistema

O sistema opera em trÃªs camadas interconectadas:

### 1. ğŸ“· Os Olhos (Edge Device)

- **Hardware:** Raspberry Pi Zero 2 W + CÃ¢mera Module v2.
    
- **FunÃ§Ã£o:** Captura de vÃ­deo e transmissÃ£o sem fio de baixa latÃªncia.
    
- **Tecnologia:**
    
    - **Captura:** `libcamera` / `rpicam-vid` (para suporte a novos OS Raspberry).
        
    - **Streaming:** Servidor Flask transmitindo MJPEG via HTTP.
        
    - **Performance:** Otimizado para 640x480 a 15 FPS para economizar bateria e banda.

### 2. ğŸ§  O CÃ©rebro Central (Cliente/PC)

- **Hardware:** Computador Local (Simulando o processamento de um Smartphone/Ã“culos Inteligente).
    
- **FunÃ§Ã£o:** OrquestraÃ§Ã£o, processamento de Ã¡udio e inteligÃªncia hÃ­brida.
    
- **Tecnologia:**
    
    - **Linguagem:** Python 3.12+.
        
    - **IA Local:** **YOLOv8 Small** (Ultralytics) para detecÃ§Ã£o de alta precisÃ£o offline.
        
    - **Interface de Voz:** `SpeechRecognition` para comandos e `gTTS` para feedback falado.
        
    - **Modo HÃ­brido:** Decide se processa a imagem localmente ou envia para a AWS com base no comando do usuÃ¡rio.

### 3. â˜ï¸ A InteligÃªncia em Nuvem (AWS Cloud)

- **Infraestrutura:** Amazon EC2 (InstÃ¢ncia Ubuntu).
    
- **FunÃ§Ã£o:** API de inferÃªncia remota para contingÃªncia e processamento leve.
    
- **Tecnologia:**
    
    - **Servidor:** Flask API (Python).
        
    - **IA Nuvem:** **YOLOv4-tiny* ou YOLOv3* (Darknet) otimizado para CPU, rodando em ambiente com Swap Memory.
        
    - **ComunicaÃ§Ã£o:** Recebe frames via HTTP POST, processa e retorna JSON com coordenadas e classes.
        

---

## ğŸ› ï¸ ConfiguraÃ§Ã£o e InstalaÃ§Ã£o

### PrÃ©-requisitos

- **Python 3.10+** instalado.
    
- **Raspberry Pi** configurada na mesma rede Wi-Fi.
    
- **Conta AWS** (opcional para o modo nuvem).
    

### ğŸ“¦ 1. Configurando a Raspberry Pi (CÃ¢mera)

No terminal da Raspberry Pi:

- Crie um VENV

```
python -m venv venv
source venv/bin/activate
```


```

# Instalar dependÃªncias
sudo apt update && sudo apt install python3-flask rpicam-apps

# Clonar/copiar o script da cÃ¢mera (camera_pi.py)

# Rodar o servidor de streaming
python3 camera_pi.py
```

_A cÃ¢mera estarÃ¡ disponÃ­vel em: `http://[IP_DA_RASPBERRY]:5000/video_feed`_

### â˜ï¸ 2. Configurando o Servidor AWS

Para rodar o YOLO em instÃ¢ncias gratuitas (t2.micro com 1GB RAM), Ã© **obrigatÃ³rio** configurar memÃ³ria virtual (Swap), caso contrÃ¡rio o processo serÃ¡ morto ("Killed") por falta de memÃ³ria.

**Passo a passo na AWS:**

1. **ConfiguraÃ§Ã£o Inicial:**
    
    - Crie uma instÃ¢ncia EC2 (Ubuntu 22.04 ou superior).
        
    - Libere a porta **5000** no Security Group.
        
    - Conecte via SSH (`ssh -i chave.pem ubuntu@IP_PUBLICO`).
        
2. **âš¡ Criar Swap Memory (Crucial para nÃ£o travar):** Rode estes comandos um por um no terminal da AWS:

    ```
    # Cria um arquivo de 2GB para memÃ³ria virtual
    sudo fallocate -l 2G /swapfile
    
    # Ajusta permissÃµes de seguranÃ§a
    sudo chmod 600 /swapfile
    
    # Formata como swap
    sudo mkswap /swapfile
    
    # Ativa o swap
    sudo swapon /swapfile
    
    # Verifica se funcionou (deve aparecer 2.0G na coluna Swap)
    free -h
    ```

3. **Crie um VENV**

	```
	python -m venv venv
	source venv/bin/activate
	```

4. **Instalar DependÃªncias:**

    ```
    sudo apt update && sudo apt install libgl1
    pip install flask opencv-python-headless numpy
    ```

5. **Baixar a IA (YOLO):**

	- Para t2.micro recomendamos:
		- yolov4-tiny para respostas mais rapidas
		- yolov3 para respostas mais precisas
	- codigo abaixo segue um exemplo com yolov3

    ```
    wget https://pjreddie.com/media/files/yolov3.weights
    wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg
    ```

6. **Iniciar o Servidor:**

    ```
    python3 server_ia.py
    ```

---
### ğŸ’» 3. Configurando o Cliente Local (PC)

No seu computador:

1. Clone este repositÃ³rio e crie um venv para projeto em sua mÃ¡quina.

```
python -m venv venv
source venv/bin/activate     # Windows: venv\Scripts\activate
```

2. Instale as dependÃªncias listadas:

    ```
    pip install -r requirements.txt
    ```

3. Edite o arquivo `eyeglass.py` com os IPs corretos:

    Python

    ```
    AWS_IP = "54.233.XX.XX"  # IP PÃºblico da sua EC2
    RASP_IP = "192.168.0.XX" # IP Local da Raspberry
    ```

4. Execute o sistema:

    ```
    python eyeglass.py
    ```
    

---

## ğŸ® Como Usar

O sistema Ã© controlado totalmente por voz para acessibilidade.

1. **Iniciar:** Ao abrir, o sistema toca um Ã¡udio de boas-vindas.
    
2. **Ativar:** Diga **"Ativar"** ou **"Iniciar"** para acordar o assistente.
    
3. **Comandos de VisÃ£o:**
    
    - ğŸ—£ï¸ _"O que tem na minha frente?"_
        
    - ğŸ—£ï¸ _"O que eu vejo?"_
        
    - _O sistema captura a imagem, analisa e responde: "Cadeira a 2 passos, Ã  sua esquerda. Vire levemente Ã  direita."_
        
4. **Troca de Modos (HÃ­brido):**
    
    - ğŸ—£ï¸ _"Modo Nuvem"_ / _"Modo AWS"_ -> Passa a processar tudo na EC2 (ideal para economizar bateria local).
        
    - ğŸ—£ï¸ _"Modo Local"_ / _"Modo PC"_ -> Volta a usar o YOLOv8 no computador (maior precisÃ£o).
        
5. **Encerrar:** Diga **"Sair"** ou **"Desligar"**.
    

---

## ğŸ“ˆ Escalabilidade e Futuro

Este MVP prova o conceito. Para transformar o EyeGlass em um produto comercial escalÃ¡vel para milhares de usuÃ¡rios, a arquitetura evoluirÃ¡ para:

### 1. Alta Disponibilidade (AWS)

- **Problema Atual:** Uma Ãºnica EC2 pode cair ou ficar lenta com muitos usuÃ¡rios.
    
- **SoluÃ§Ã£o Futura:**
    
    - **Docker & ECS:** Empacotar o cÃ³digo da IA em containers Docker.
        
    - **Auto Scaling:** Usar AWS ECS (Fargate) para subir novos containers automaticamente quando a demanda aumentar.
        
    - **Load Balancer (ALB):** Distribuir as requisiÃ§Ãµes dos Ã³culos entre vÃ¡rios servidores.

### 3. App Mobile

- Substituir o cÃ³digo Python do PC por um **Aplicativo Android/iOS** que se comunica via Bluetooth/wifi com os Ã³culos (Raspberry) e gerencia a conexÃ£o com a nuvem AWS.
    

---

## ğŸ“‚ Estrutura do RepositÃ³rio


```
/
â”œâ”€â”€ eyeglass.py               # [PC] CÃ³digo Principal (Cliente/CÃ©rebro HÃ­brido)
â”œâ”€â”€ server_ia.py              # [AWS] API Server (Flask + YOLOv3)
â”œâ”€â”€ camera_pi.py              # [Raspberry] Streamer de VÃ­deo
â”œâ”€â”€ requirements.txt          # DependÃªncias do projeto
â”œâ”€â”€ README.md                 # DocumentaÃ§Ã£o
â””â”€â”€ audios                 	  # Pasta com audios personalizados para voz
```

---

## ğŸ¤ Autor

Desenvolvido por **EYEGEN**. Projeto de MVP focado em acessibilidade, visÃ£o computacional e arquitetura de nuvem.
